import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, random_split
from dataloader_test import EVEyeDataset
from model import DualStreamGazeModel
import os

# ================= 0. è¶…åƒæ•¸è¨­å®š =================
# è·¯å¾‘ç›´æ¥æŒ‡å‘ session_1_0_2 (å› ç‚ºä½ çš„ npy æª”åœ¨é‚£è£¡)
SESSION_DIR = r"D:\Peggy\EV-Eye\Data\session_1_0_2"
BATCH_SIZE = 8
LEARNING_RATE = 1e-4
EPOCHS = 10
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

print(f"ğŸš€ è¨“ç·´è£ç½®: {DEVICE}")

# ================= 1. æº–å‚™è³‡æ–™ =================
print("ğŸ“‚ è¼‰å…¥è³‡æ–™é›†...")
full_dataset = EVEyeDataset(session_dir=SESSION_DIR)

# ç°¡å–®åˆ‡åˆ† 80% è¨“ç·´, 20% é©—è­‰
train_size = int(0.8 * len(full_dataset))
val_size = len(full_dataset) - train_size
train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)

print(f"ğŸ“Š è¨“ç·´é›†: {len(train_dataset)} ç­† | é©—è­‰é›†: {len(val_dataset)} ç­†")

# ================= 2. å»ºç«‹æ¨¡å‹ =================
model = DualStreamGazeModel().to(DEVICE)
criterion = nn.MSELoss() # é æ¸¬åº§æ¨™çš„å‡æ–¹èª¤å·®
optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)

# ================= 3. è¨“ç·´è¿´åœˆ =================
print("ğŸ é–‹å§‹æ­£å¼è¨“ç·´ (Real Training)...")

for epoch in range(EPOCHS):
    # --- Training Phase ---
    model.train()
    total_loss = 0
    
    for i, (images, events, labels) in enumerate(train_loader): # ğŸ”¥ é€™è£¡ç¾åœ¨æœ‰ labels äº†
        images, events, labels = images.to(DEVICE), events.to(DEVICE), labels.to(DEVICE)
        
        optimizer.zero_grad()
        outputs = model(images, events) # Output: (Batch, 2)
        loss = criterion(outputs, labels) # èˆ‡çœŸæ¨™ç±¤è¨ˆç®— Loss
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()
        
        if (i+1) % 50 == 0:
            print(f"   [Epoch {epoch+1}] Step [{i+1}/{len(train_loader)}] Loss: {loss.item():.4f}")

    avg_loss = total_loss / len(train_loader)
    
    # --- Validation Phase (è€ƒè©¦æ™‚é–“) ---
    model.eval()
    val_loss = 0
    with torch.no_grad():
        for images, events, labels in val_loader:
            images, events, labels = images.to(DEVICE), events.to(DEVICE), labels.to(DEVICE)
            outputs = model(images, events)
            loss = criterion(outputs, labels)
            val_loss += loss.item()
    avg_val_loss = val_loss / len(val_loader)

    print(f"âœ¨ Epoch [{epoch+1}/{EPOCHS}] Train Loss: {avg_loss:.4f} | Val Loss: {avg_val_loss:.4f}")
    
    # å„²å­˜æœ€å¥½çš„æ¨¡å‹
    if epoch == 0 or avg_val_loss < best_val_loss:
        best_val_loss = avg_val_loss
        torch.save(model.state_dict(), os.path.join(SESSION_DIR, "best_model.pth"))
        print("   ğŸ’¾ æ¨¡å‹å·²å„²å­˜ (New Best!)")

print("ğŸ‰ è¨“ç·´çµæŸï¼æ¨¡å‹å·²å­˜ç‚º best_model.pth")