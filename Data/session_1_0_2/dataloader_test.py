import torch
from torch.utils.data import Dataset
import numpy as np
import os
import cv2

# ================= 1. äº‹ä»¶è™•ç†æ ¸å¿ƒ (ä¿®æ­£ç‰ˆ) =================
def events_to_voxel_grid(events, num_bins, width, height):
    """
    å°‡äº‹ä»¶æµè½‰æ›ç‚º Voxel Grid (Time_Bins, Height, Width)
    """
    # 1. å¦‚æœæ²’æœ‰äº‹ä»¶ï¼Œå›å‚³å…¨é›¶ Tensor
    if len(events) == 0:
        return torch.zeros((num_bins, height, width), dtype=torch.float32)

    # 2. å»ºç«‹ç©ºçš„ NumPy é™£åˆ— (ğŸ”¥ ä¿®æ­£é»ï¼šä½¿ç”¨ np.float32)
    voxel_grid = np.zeros((num_bins, height, width), dtype=np.float32)
    
    t = events[:, 0]
    
    # é¿å…åªæœ‰ä¸€ç­†è³‡æ–™å°è‡´é™¤ä»¥é›¶ï¼Œæˆ–æ™‚é–“é•·åº¦ç‚º 0
    if len(t) < 2 or (t[-1] - t[0] == 0):
         return torch.from_numpy(voxel_grid)

    # æ­£è¦åŒ–æ™‚é–“æˆ³
    duration = t[-1] - t[0] + 1e-6 # åŠ ä¸€å€‹æ¥µå°å€¼é¿å…é™¤ä»¥é›¶
    t_norm = (t - t[0]) / duration * (num_bins - 1)
    
    x = events[:, 1].astype(int)
    y = events[:, 2].astype(int)
    p = events[:, 3]

    # ç´¯ç©äº‹ä»¶åˆ° Voxel Grid
    for i in range(len(events)):
        t_idx = int(t_norm[i])
        # é‚Šç•Œæª¢æŸ¥
        if 0 <= t_idx < num_bins and 0 <= y[i] < height and 0 <= x[i] < width:
            val = 1.0 if p[i] == 1 else -1.0
            voxel_grid[t_idx, y[i], x[i]] += val
            
    return torch.from_numpy(voxel_grid)

# ================= 2. Dataset é¡åˆ¥ (å«æ¨™ç±¤è®€å–) =================
class EVEyeDataset(Dataset):
    def __init__(self, session_dir):
        self.session_path = session_dir
        
        # è¨­å®šæª”æ¡ˆè·¯å¾‘
        self.events_path = os.path.join(self.session_path, 'events', 'events.txt')
        self.frames_path = os.path.join(self.session_path, 'frames')
        self.labels_path = os.path.join(self.session_path, 'gaze_labels.npy') # è®€å–è™•ç†å¥½çš„æ¨™ç±¤

        print(f"ğŸ“‚ åˆå§‹åŒ– Dataset: {self.session_path}")

        # 1. è®€å–åœ–ç‰‡åˆ—è¡¨
        if os.path.exists(self.frames_path):
            self.image_files = sorted([f for f in os.listdir(self.frames_path) if f.endswith('.png')])
        else:
            self.image_files = []
            print("âŒ æ‰¾ä¸åˆ° frames è³‡æ–™å¤¾")

        # 2. è®€å–æ¨™ç±¤ & éæ¿¾ç„¡æ•ˆè³‡æ–™
        self.valid_indices = [] # å­˜æ”¾æœ‰æ•ˆè³‡æ–™çš„ç´¢å¼•å°ç…§è¡¨
        
        if os.path.exists(self.labels_path):
            self.labels = np.load(self.labels_path)
            
            # ç¯©é¸å‡ºæ¨™ç±¤ä¸æ˜¯ (-1, -1) çš„ç´¢å¼•
            # ç¢ºä¿åœ–ç‰‡æ•¸é‡è·Ÿæ¨™ç±¤æ•¸é‡ä¸€è‡´æ‰èƒ½é€²è¡Œå°æ‡‰
            limit = min(len(self.labels), len(self.image_files))
            
            for i in range(limit):
                # æª¢æŸ¥æ¨™ç±¤æ˜¯å¦æœ‰æ•ˆ (æˆ‘å€‘åœ¨ step7 è¨­å®šç„¡æ•ˆå€¼ç‚º -1)
                if self.labels[i][0] != -1:
                    self.valid_indices.append(i)
                    
            print(f"âœ… è¼‰å…¥æ¨™ç±¤æˆåŠŸï¼æœ‰æ•ˆè³‡æ–™: {len(self.valid_indices)} / {limit}")
        else:
            print("âŒ æ‰¾ä¸åˆ° gaze_labels.npyï¼Œè«‹å…ˆåŸ·è¡Œ step7ï¼")
            self.labels = None
            # å¦‚æœæ²’æœ‰æ¨™ç±¤æª”ï¼Œç‚ºäº†æ¸¬è©¦ç¨‹å¼ç¢¼ï¼Œæš«æ™‚å‡è¨­æ‰€æœ‰åœ–ç‰‡éƒ½æœ‰æ•ˆ (ä½†æ¨™ç±¤æœƒéŒ¯)
            self.valid_indices = list(range(len(self.image_files)))

        # 3. è®€å–äº‹ä»¶ (ä½¿ç”¨ float64 é¿å…ç²¾åº¦å•é¡Œ)
        if os.path.exists(self.events_path):
            self.all_events = self._load_events_txt(self.events_path)
        else:
            self.all_events = np.array([])
            print("âŒ æ‰¾ä¸åˆ° events.txt")

    def _load_events_txt(self, path):
        # è®€å–äº‹ä»¶æ–‡å­—æª”
        events = []
        with open(path, 'r') as f:
            for line in f:
                if line.strip():
                    try:
                        events.append(list(map(float, line.split())))
                    except ValueError:
                        continue
        # é‡è¦ï¼šä½¿ç”¨ float64 ä¿å­˜å¾®ç§’ç´šæ™‚é–“æˆ³
        return np.array(events, dtype=np.float64)

    def __len__(self):
        # Dataset çš„é•·åº¦æ˜¯ã€Œæœ‰æ•ˆè³‡æ–™ã€çš„æ•¸é‡
        return len(self.valid_indices)

    def __getitem__(self, idx):
        # ä½¿ç”¨æœ‰æ•ˆç´¢å¼•å°ç…§è¡¨æ‰¾åˆ°çœŸå¯¦çš„ index
        real_idx = self.valid_indices[idx]
        
        # --- A. è®€å–åœ–ç‰‡ ---
        img_name = self.image_files[real_idx]
        img_path = os.path.join(self.frames_path, img_name)
        
        image = cv2.imread(img_path)
        if image is None:
            # é˜²å‘†æ©Ÿåˆ¶
            return torch.zeros((3, 260, 346)), torch.zeros((5, 260, 346)), torch.zeros(2)
        
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        # è½‰ Tensor: (H, W, C) -> (C, H, W) ä¸¦æ­£è¦åŒ–åˆ° 0~1
        image_tensor = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0

        # --- B. è®€å–æ¨™ç±¤ ---
        if self.labels is not None:
            label = self.labels[real_idx]
            label_tensor = torch.tensor(label, dtype=torch.float32)
        else:
            label_tensor = torch.zeros(2, dtype=torch.float32)

        # --- C. è®€å–å°æ‡‰äº‹ä»¶ (20ms è¦–çª—) ---
        try:
            # å¾æª”åè§£ææ™‚é–“æˆ³
            ts_str = img_name.split('_')[-1].replace('.png', '')
            current_ts = float(ts_str)
        except:
            current_ts = 0.0
            
        window = 20000 # 20ms = 20000us
        local_events = np.array([])

        if len(self.all_events) > 0:
            # ç¢ºä¿æœå°‹ç¯„åœåˆç†
            start_time = current_ts - window
            
            # ä½¿ç”¨ Boolean Mask å¿«é€Ÿç¯©é¸
            # å„ªåŒ–ï¼šå…ˆæª¢æŸ¥æ˜¯å¦åœ¨æ•´å€‹äº‹ä»¶æµç¯„åœå…§
            if current_ts >= self.all_events[0, 0]:
                mask = (self.all_events[:, 0] >= start_time) & (self.all_events[:, 0] <= current_ts)
                local_events = self.all_events[mask]
        
        # è½‰æ›ç‚º Voxel Grid
        event_voxel = events_to_voxel_grid(local_events, num_bins=5, width=346, height=260)
        
        return image_tensor, event_voxel, label_tensor

# ================= è‡ªæˆ‘æ¸¬è©¦å€å¡Š =================
if __name__ == "__main__":
    # ç°¡å–®æ¸¬è©¦è®€å–
    print("ğŸš€ æ¸¬è©¦ DataLoader...")
    dataset = EVEyeDataset(session_dir=".")
    if len(dataset) > 0:
        img, evt, lbl = dataset[0]
        print(f"âœ… è®€å–æˆåŠŸï¼")
        print(f"å½±åƒå½¢ç‹€: {img.shape}")
        print(f"äº‹ä»¶å½¢ç‹€: {evt.shape}")
        print(f"æ¨™ç±¤æ•¸å€¼: {lbl}")
    else:
        print("âš ï¸ æ²’æœ‰è³‡æ–™å¯è®€å–")